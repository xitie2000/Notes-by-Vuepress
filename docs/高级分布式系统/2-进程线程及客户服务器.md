#  Chapter 2 进程线程及客户服务器

## 1 进程

### 1.1 简介

进程是一个具有一定独立功能的程序关于某个数据集合的一次运行活动

- 进程是系统资源分配的基本单元
- 在早期面向进程设计的计算机结构中，是系统基本的执行单元或者说调度单元
- 在当代面向线程设计的计算机结构中，是线程的容器

多个不同的进程运行的可以是相同的程序：一个程序在不同的数据集里就构成不同的进程，能得到不同的结果；但是执行过程中，程序一般不发生改变

### 1.2 五状态进程模型

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221029164705.png" style="zoom:80%;" />

### 1.3 进程的特点

- 动态性：进程的实质是程序在多道程序系统中的一次执行过程，进程是动态产生，动态消亡的
- 并发性：任何进程都可以同其他进程一起并发执行
- 独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位
- 异步性：由于进程间的相互制约，使进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进
- 结构特征：进程由程序、数据和进程控制块三部分组成

## 2 线程

### 2.1 线程的引入

- 进程的引入提高了计算机资源的利用效率。但在进一步提高进程的并发性时，人们发现进程切换开销占的比重越来越大，同时进程间通信的效率也受到限制
- 线程的引入正是为了简化进程间的通信，降低运行实体间切换的开销，提高进程内的并发程度
- 线程：有时称轻量级进程，进程中的一个运行实体，是一个CPU调度单位，资源的拥有者还是进程
- 多线程进程：一个线程被阻塞时，可运行同一进 程中的另一线程

### 2.2 线程模型

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221029165539.png" style="zoom:80%;" />

### 2.3 线程编程

```java
public class MyThread extends Thread {
    int count = 1, number;
    public MyThread(int num) {
        number = num;
        System.out.println("Create thread" + number);
    }
    public void run() {
        while (true) {
            System.out.println("Thread " + number + ":count " + count);
            if (++count == 6) return;
        }
    }
    public static void main(String args[]) {
        for (int i = 0; i < 5; i++) new MyThread(i + 1).start();
    }
}
```

第一次运行

![](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221029170632.png)

第二次运行

![](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221029170741.png)

### 2.4 理解线程

- 线程是进程的一个实体，可作为系统独立调度的基本单位
  - 有执行状态（状态转换：阻塞、就绪、运行）
  - 不运行时保存上下文:每个线程有自己的程序计数器、堆栈（局部变量）、状态等
- 调度：线程作为调度的基本单位，同进程中线程切换不引起进程切换，当不同进程的线程切换才引起进程切换
  - 线程间切换时，系统开销小、切换快
- 并发性：一个进程内的多个线程可并发
- 拥有资源：线程仅拥有隶属进程的资源；进程是拥有资源的独立单位
  - 进程的多个线程都在该进程的地址空间活动，可共享该进程的资源

### 2.5 使用线程的优点和应用场合

- 线程间切换时，系统开销小、切换快
- 线程间共享进程资源，通信方便
- 适宜的应用场合
  - 非计算密集型任务，有比较多的IO操作
    - 如：接收数据、处理数据、备份数据可考虑设计3个控制线程，不会因为某个线程阻塞，导致整个进程被阻塞
  - 有多核CPU
  - 进程间通信代价太大
  - 需要并发
- **线程的数量也不是越多越好，合适最好**

### 2.6 线程池

- 虽然线程的创建成本比较低，但也需要空间的初始化工作等，还是有一定的开销
- 线程池就是一个存放线程的池子，当需要线程时可以从池中取出线程，当不需要线程时将线程放还池中
  - 实现了线程的重复利用，减少了线程频繁创建和销毁带来的开销
- 相似概念：数据库的连接池

### 2.7 线程与并发

- 线程允许在同一个进程中同时存在多个线程控制流，每个线程有各自的程序计数器、栈和局部变量，同一个程序中的多个线程可以被同时调度到多个CPU上运行
- 当多个线程要争夺资源的时候，就需要进行并发控制，如
  - 锁机制：`synchronized(object){ }`
- 并发与并行：并发是同一时间应对（dealing with）多件事情的能力，宏观上同时，微观上不断切换；并行是同一时间动手做（doing）多件事情的能力，宏观和微观都是同时

### 2.8 多进程与多线程

- 对需要利用多核性能又想实现资源完全隔离的情况，选择多进程
- 对需要利用多核性能但不要实现资源完全隔离的情况，选择多线程
- 对希望提升核内CPU利用率的情况，则选择多协程（纤程）

### 2.9 使用例

#### 2.9.1 客户程序中的多线程

- 以web浏览器为例，web文档由HTML文件组成，包含文本文件、图像组、图标等，须建立TCP/IP的连接，建立连接和读取数据都可能导致阻塞
- 以多线程的方式开发浏览器，激活多个线程，每个线程都与服务器建立独立连接获取数据，每个线程负责获取页面的相应部分

#### 2.9.2 Server侧的多线程

如多线程的Web服务器

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221029172633.png" style="zoom: 67%;" />

### 2.10 提醒

- 由于线程并不像进程那样彼此隔离，在单个进程中共享资源的并发控制问题由应用程序开发者负责解决
- 因此多线程应用程序的开发需要付出更多的努力
- 设计要合理，实现要简单

## 3 IO 模型

### 3.1 简介

- 与CPU的性能相比，IO操作的速率是比较低的
- 在软件设计中，需要对IO操作进行协调，降低输入输出操作对其他操作的影响
  - 这种协调体现在不同IO模型选择上
- 基于阻塞/非阻塞、同步/异步等，可将IO模型分为5类
  - 阻塞式IO模型 BIO
  - 非阻塞式IO模型
  - 信号驱动式IO模型
  - 复用式IO模型 NIO
  - 异步式IO模型 AIO

#### 参考资料

<a href="http://www.360doc.com/content/18/0624/05/56167096_764796454.shtml" target="_blank">IO的概念和5种IO模型</a>

<a href="https://www.cnblogs.com/sky-heaven/p/10689484.html" target="_blank">Linux select 与 阻塞( blocking ) 及非阻塞 (non blocking)实现io多路复用的示例【转】 - sky-heaven - 博客园 (cnblogs.com)</a>

### 3.2 同步与异步  阻塞与非阻塞

#### 3.2.1 同步与异步

同步与异步指的是 **调用方和被调用方之间的消息通信机制**

- 如果调用方调用某个操作，直到操作结束时调用方才能获得一个回答的结果，那么这个操作就是同步的
- 如果调用方调用某个操作，被调用方立刻给出一个不包含结果的回应，然后等被调用方得到结果时再主动通知调用方，那么这个操作就是异步的

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030112640.png" style="zoom:80%;" />

#### 3.2.2 阻塞与非阻塞

阻塞与非阻塞的区别在于调用方在调用操作之后，等待返回结果时的状态

- 阻塞：在调用结果返回前，当前线程会被挂起，并在得到结果之后返回
- 非阻塞：如果不能立刻得到结果，则不会阻塞当前线程。因此对应非阻塞的情况，调用者需要定时轮询查看处理状态

#### 3.2.3 组合

- 同步操作可以是阻塞的，也可以是非阻塞的

  - 如果一个同步操作是阻塞的，调用方调用这个服务后会被挂起，直到收到回答
  - 如果一个同步操作是非阻塞的，调用方调用这个服务后可以继续进行其它工作，之后通过继续调用的方法获取结果

  <img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030113022.png" style="zoom:80%;" />

- 对于异步操作来说，讨论阻塞和非阻塞没有意义

  - 异步操作的请求会被立刻回应，调用方拿到回应就可以继续其他工作，直到接收到回调结果时再处理操作结果即可

  <img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030113143.png" style="zoom:80%;" />

- 所以“阻塞式IO”指同步阻塞式IO，非阻塞式IO指同步非阻塞IO

### 3.3 操作缓存的IO基本模型

- 操作系统和驱动程序运行在内核空间，应用程序运行在用户空间
- 应用程序必须通过系统调用请求kernel来协助完成IO动作，内核会为每个IO设备维护一个缓冲区
- 在存在缓存的IO模型中，数据读操作被划分为两个阶段
  - 接收阶段：数据从接口到缓存
  - 复制阶段：数据从缓存到应用程序内存，**IO的同步异步看这个阶段**
  - 数据写操作类似，只是两个阶段的顺序序和数据流向不同

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030113412.png" style="zoom:80%;" />

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030113431.png" style="zoom:80%;" />

### 3.4 几种 IO 模型

#### 3.4.1 阻塞式 IO 模型

- 阻塞式IO（Blocking IO，BIO）是最为常见的IO模型，它是同步的、阻塞的

  调用方调用IO操作后，调用方线程被挂起，直到数据接收阶段、复制阶段全部完成后，调用方线程才被唤醒

- 典型应用：阻塞式Socket，Java BIO

- 使用简单，但只适合IO较少的场景

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030113718.png" style="zoom:80%;" />

#### 3.4.2 非阻塞式 IO 模型

- 非阻塞式IO（Non-blocking IO）

  调用方调用IO操作后，会立刻收到一个回应，不会被挂起，如果回应是接受阶段没准备好，调用方可以通过不断地轮询来判断接受过程是否完成，并可以在轮询的间隙进行其他操作

- 典型应用：Socket 设置 NONBLOCK

- 该模型并不常用，而是常作为后面几种模型的基础

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030113947.png" style="zoom:80%;" />

#### 3.4.3 信号驱动式 IO 模型

- 信号驱动式IO模型
  - 调用方向内核注册一个信号处理函数，然后返回不阻塞。当内核数据就绪时会发送一个信号给调用方，用户进程便在信号处理函数中调用IO读取数据
  - 需要调用方设置回调函数（信号处理程序）
- 该模型并不常用，常作为后面几种模型的基础

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030114147.png" style="zoom:80%;" />

#### 3.4.4 复用式IO模型（IO多路复用）

- 复用式IO模型

  调用方将多个IO操作委托给一个监听函数（如select），然后调用方线程被阻塞，当多个IO操作中有一个或多个接收阶段完成时，调用方被唤醒，可以直接操作接收阶段已完成的IO

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030114334.png" style="zoom:80%;" />

- 复用式IO模型可基于非阻塞IO实现也可以基于信号式IO实现
- 典型应用：Java NIO、Nginx（epoll、poll、select）
  - Java NIO（可理解为 New IO）
- 提醒：Java和Tomcat中的NIO其实都是复用式IO模型而不是非阻塞IO模型

##### select、poll、epoll

- select、poll、epoll都是IO多路复用的机制
  - select：$O(n)$，它仅仅知道有 I/O 事件发生了，却并不知道是哪几个流，需要调用方无差别轮询所有流，找出能读出数据，或者写入数据的流，对它进行操作
  - poll： $O(n)$，本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的
  - epoll：$O(1)$，可以理解为event poll，会把哪个流发生了怎样的 I/O 事件通知调用方，此时对这些流的操作是准确的
- 表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，因为epoll的通知机制需要很多函数回调，选择哪种基于应用的需求

#### 3.4.5 异步式 IO

- 异步式IO模型（Asynchronous IO，AIO）

  要进行IO操作时，调用方发起 aio_read 或类似操作，给内核传递描述符、缓冲区指针、缓冲区大小等参数，并告诉内核当整个操作完成时，如何通知调用方。内核收到 aio_read 之后会立刻回应，然后内核会等待数据准备完成，**并将数据拷贝到用户内存**。之后，内核给用户进程发送一个信号，告诉它 aio_read 操作完成了

- 典型应用：Java 7 AIO

- 需要操作系统的底层支持

  - Linux 2.5 版本内核首次出现，2.6 版本产品的内核标准特性

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030115128.png" style="zoom:80%;" />

### 3.5 IO 模型总结

- 最常用的IO模型是阻塞式IO模型BIO、复用式IO模型NIO和异步式IO模型AIO
  - BIO是最传统也是性能最差的IO模型，每个操作占用一个线程，但编程简单，适合读写操作较少的场合
  - NIO可以极大地减少IO操作对线程的占用，提升IO操作的并发能力，适合IO操作频繁的场合
  - AIO比NIO性能更高，如果编程语言支持这种模型，则可以应用到高读写应用中，以提升IO性能
- 同异步IO的根本区别：数据怎么从内核缓存到达用户空间的
  - 同步IO：用户线程主动调用recvfrom将数据拷贝到用户空间
  - 异步IO：用户线程将整个工作交给内核，**由内核完成将数据拷贝到用户内存的工作**，然后发信号通知。在此期间，用户线程不需要去检查IO操作的状态、也不需要主动地去拷贝数据

## 4 客户

### 4.1 客户程序的设计

- 客户程序的主要目的是帮助用户与远程服务器交互
- 根据需要可有多种设计思路，如

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030115454.png" style="zoom:80%;" />

### 4.2 客户程序对分布透明性的支持例

- 复制透明性：使用资源的多个副本提升性能和可靠性，而客户无需知道副本的相关信息
- 可使用客户端实现服务器复制透明性

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030115549.png" style="zoom:80%;" />

## 5 服务器

### 5.1 简介

- 服务器是实现特定服务的进程，这些服务是为一组客户提供的
- 本质上，每个服务器的工作方式都是一样的：等待来自客户的请求，随后负责处理该请求，然后等待下一个请求
- 一般情况下，服务器同时为多个客户提供服务，因此，同一时刻可能会有多个请求到来
  - 并发服务器
  - 迭代服务器

#### 5.1.1 并发服务器

并发服务器：接收连接或请求的进程或线程自己不处理，而是将连接或请求传递给其它进程或线程来处理， 自身立即返回并等待下一个连接或请求

- 如：多线程服务器
- 再如：每收到一个请求都派生出一个新的进程来进行处理
- 由处理请求的线程或者进程负责向发出该请求的客户端返回响应

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030133512.png" style="zoom:80%;" />

#### 5.1.2 迭代服务器

迭代服务器：自己处理连接和请求，并在必要的情况下将响应返回给发出请求的客户。

可以实现高并发

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030133745.png" style="zoom:80%;" />

### 5.2 客户与服务器的连接

#### 5.2.1 客户如何联系服务器

- 客户如何知道服务器的IP地址？
  - 众所周知IP地址、 DNS、命名服务
- 客户总是需要向服务器所在的某个端口（Port）发送请求，而服务器应该在这个端口监听请求
- 客户如何知道某个服务所对应的端口？
  - 方法1：为已知服务分配一个众所周知的端口
    - FTP 21
    - HTTP 80
  - 方法2：服务器的端口被本地操作系统动态分配，客户必须找到该端口
    - 怎么找到？见下一小节

#### 5.2.2 客户到服务器的两种绑定策略

##### 方法一：守护进程

- 在运行服务器的每台机器上运行一个特殊的守护进程 daemon

- 该进程负责跟踪位于同一台机器上的每一个服务进程使用的当前端点
- 该进程监听一个已知的端口，客户通过这个端口与该守护进程进行联系，得到服务器的端口

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030134224.png" style="zoom:80%;" />

##### 方法二：超级服务器

- 如Unix中的inetd守护程序，监听许多Internet服务的已知端口
- 当收到请求的时候，它派生出一个进程以对该请求进行进一步处理，这个派生出的进程在处理完毕后自动退出运行

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030134351.png" style="zoom:80%;" />

#### 5.2.3 客户对服务器工作的中断方法

- 方法1：让用户强行退出客户应用程序（这将中断与服务器的连接）然后马上重新启动客户程序，就好像什么事情都没有发生一样。
  - 看起来比较笨，但在互联网环境下工作得挺好
- 方法2：使用带外数据
  - 利用单独另外的控制端点
  - 利用同一链路，如，TCP中发送urgent data

### 5.3 服务器状态

- 永久状态和会话状态
  - 永久状态记录的通常是数据库数据，如客户信息
  - 会话状态是服务器与一个客户间一次会话中涉及的信息、数据
    - 会话(Session) 是通信双方从开始通信到通信结束期间的一个上下文（Context）
- 服务器（进程）的状态问题通常关注的是 **会话状态**
  - 当然很多应用也会用到永久状态

#### 5.3.1 有状态服务器

- 有状态服务器：服务器保存会话状态，同一会话的请求之间有关联，即请求的响应结果与该会话之前的请求有关
  - 网络游戏服务器：在服务端维护每个连接的状态信息，服务端在接收到每个连接发送的请求时，可以从本地存储的信息来重现上下文关系
- 优点：方便建立与客户间的会话关系，支持有状态的服务
- 缺点：
  - 服务端保存大量数据，增加服务端压力
  - 客户端请求依赖服务端，同一会话（甚至同一客户）的多次请求必须访问同一台服务器
  - 服务端保存用户状态，难以进行水平扩展（增加服务器数量）
  - 服务器发生故障时，状态恢复比较困难

#### 5.3.2 无状态服务器

- 无状态服务器：服务器不存储会话状态，处理一次请求所需的全部信息，要么都包含在这个请求里，要么可以根据这个请求携带的信息从外部获取到（比如说数据库）
  - 例如，Web服务器：每次HTTP请求和以前的请求没有直接关联，仅仅对这次的HTTP请求作出响应，如获取一个文件
    - HTTP是无状态协议
- 优点：
  - 客户端请求不依赖服务端的信息，任何多次请求不需要必须访问到同一台服务器，服务器副本之间不需要进行状态同步
  - 服务器发生故障时，不需要进行状态恢复
  - 服务端可以方便地进行水平扩展
- 缺点：支持有状态的服务比较困难

#### 5.3.3 用无状态服务器实现有状态服务

在某些情况下，服务器需要保留客户的活动记录，如Web服务器可以将客户引导到该客户最常浏览的页面

实现方式例：使用cookie，cookie 是一小段数据，包含对服务器有用的针对特定客户的信息，存储在浏览器中。客户每次访问该服务器时，相关Cookie将与请求一起发送给服务器，再基于Cookie信息获取该会话必要的信息

- 如保存用户的登录信息，会话ID。对用户是透明的
- 缺点：违反隐私权，有安全性隐患（仿冒ID）

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030135416.png" style="zoom:80%;" />

**其他方法：**

<a href="https://www.zhihu.com/question/19786827/answer/2064471064" target="_blank">COOKIE和SESSION有什么区别？ - 码海的回答 - 知乎</a>

##  6 服务器集群

### 6.1 简介

服务器集群是一组通过网络连接的机器，每台机器运行一个或多个服务器（进程）

- 这里讨论的服务器集群是指在一个数据中心中的机器集群，能提供高带宽和低延迟
- 云计算技术特别适合搭建服务器集群

一般，集群系统中的每个节点都运行同样的程序

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030135829.png" style="zoom:80%;" />

### 6.2 集群的种类

#### 6.2.1 无状态服务的节点集群

最容易实现单节点到多节点集群扩展的是无状态服务器

- 扩展方便
- 请求分发也很方便，每来一个请求都可以直接进行分发，不需要依赖以前分发的情况

例如：用户先后发出r1和r2两个请求，无论r2和r1分发去的节点是否一致，响应结果都相同

#### 6.2.2 有状态服务的集群方法

许多服务都是有状态的，用户的历史请求在系统中组成了用户信息（永久状态、会话状态），系统必须结合用户信息对用户的请求进行回应

多种方法可供选择

- 单一服务节点集群
- 信息共享的节点集群
- 信息一致的节点集群

##### 单一服务节点集群

- 是实现有状态服务集群的最简单方法，节点之间是隔离的
  - 任意用户都有一个对应的节点，该节点上保存有该用户信息
  - 用户的请求总是分发到与之对应的节点上
- 虽然集群包含了多个节点，但服务某个用户的（或某个用户会话的）始终是同一节点，因此可将这类集群称为单一服务节点集群
  - 容错性较差
- 用户节点间关系的建立与维护方法例
  - 用户注册时由用户选择节点，如一些游戏服务
  - 用户注册时根据用户所处网络分配节点，如一些邮件服务
  - 用户注册时根据用户id分配节点，如一些聊天系统
  - 在用户登录时随机或根据规则分配节点，将分配节点写入Cookie，随后的请求根据携带的Cookie分发到之前分配的节点
    - 只保证用户对应的节点在一次会话周期内不会改变

##### 信息共享的节点集群

- 集群中所有节点连接到一个公共的信息池中，并在这个信息池中存储所有用户信息
  - 信息池可以是传统数据库， NoSQL、NewSQL库等
- 通常服务节点和信息池部署在不同的机器上，可以通过部署多个服务节点的方式来扩展集群
- 在此类集群中，每个节点都从信息池中读写用户状态，因此对于用户来说，每个节点都是等价的
- 但此类系统会受到信息池容量、读写性能的影响

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030140458.png" style="zoom:80%;" />

##### 信息一致的节点集群

- 此类集群中，每个节点独立拥有自身的信息池，但是，为了继续保证系统提供有状态的服务，必须保证各个信息池中的数据信息是一致的
  - 不同系统可以选择不同的一致性
- 此类集群适合用在读多写少的场景
  - 节点间信息同步较少发生
  - 充分发挥多个信息池的并行优势

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030140627.png" style="zoom:80%;" />

### 6.3 负载均衡

负载均衡：负责调度后方的多台机器，以统一的接口对外提供服务

大型系统的负载均衡常常是多级的

- 这里仅简要介绍请求进入数据中心入口之后的负载均衡器LB

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030140843.png" style="zoom:80%;" />

#### 6.3.1 负载均衡分类

负载均衡基于工作的协议层次可划分为两类

- 四层负载均衡：主要根据连接信息（TCP）或者本身的特征（源IP，目标IP）等进行均衡
  - 四层是多种均衡器工作模式的统称，它们工作模式的共同特点是维持同一个TCP连接，而不是只工作在四层
    - 可能需要改写MAC地址、IP地址、TCP/UDP的端口号等
  - 优势：性能高
- 七层负载均衡：在应用层进行工作，可以根据请求报文的内容进行调度，如可以基于域名（如HTTP头里的 Host）、URL、Cookie、Header等进行均衡
  - 优势：功能强

##### 四层负载均衡例：LVS四层

- LVS（Linux virtual server），Linux虚拟服务器

  - 因为LVS自身是个负载均衡器(director)，不直接处理请求，而是将请求转发至位于它后端真正的服务器上

- LVS是章文嵩开发的一个国产开源负载均衡软件。LVS最初是他在大学期间写的，随着后来使用的用户越来越多，LVS也越来越完善，最终集成到了Linux的内核中，因此性能高

- LVS用的最多的是四层负载均衡功能的ipvs

- 支持多种模式，如LVS-NAT

  ![](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/image-20221030141233720.png)

- NAT服务器必须作为实际服务器的网关，否则数据包被转发后将一去不返

##### 七层负载均衡

- 四层负载均衡工作模式都属于转发
  - 客户端与响应请求的真实服务器维持着同一条TCP通道
- 工作在四层之上的负载均衡模式就无法再转发了，只能代理，即真实服务器、负载均衡器、客户端三者之间由两条独立的TCP通道来维持通信
- “代理”根据“哪一方能够感知到”的原则，可分为三类：正向代理、反向代理、透明代理

![](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030141415.png)

###### 正向代理

- 正向代理：在客户端设置的，代表客户端与服务器通信的代理服务，客户端可知，对服务器透明
  - 客户端必须设置正向代理服务器，即要知道正向代理服务器的IP地址， 还有代理程序的端口
- 作用例
  - 访问本无法访问的服务器
  - Cache
  - 客户端访问授权
  - 隐藏访问者的行踪

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030141631.png" style="zoom:80%;" />

###### 反向代理

- 反向代理：在服务器侧设置的，代表真实服务器与客户端通信的代理服务，对于客户端来说是透明的
- 作用例
  - 集群式部署实现负载均衡
  - 保护和隐藏原始资源服务器
  - Cache

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030141732.png" style="zoom:80%;" />

###### 透明代理

- 透明代理：对客户端和服务器端双方都透明的代理服务，配置在网络中间设备上，可以拦截TCP/IP层数据流量，可以改变HTTP请求报文等。例如
  - 可用于一些公司使用的行为管理软件

<img src="https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030141816.png" style="zoom:90%;" />

##### 七层负载均衡例：Nginx

- 七层负载均衡器属于反向代理
- Nginx是一款高性能的反向代理服务器；也是一个IMAP、POP3、SMTP代理服务器；也是一个Http服务器
  - 即Nginx本身就可以托管网站，进行Http服务处理，也可以作为反向代理服务器使用
- 具有占有内存少，稳定性高等优势，并且依靠并发能力强，丰富的模块库以及友好灵活的配置而闻名
  - 在Linux操作系统下，nginx使用epoll事件模型，效率非常高
  - 支持简单的容错和利用算法进行负载均衡
  - 支持热部署，启动速度特别迅速，因此可以在不间断服务的情况下，对软件版本或者配置进行升级

###### Nginx进程模型

- 默认情况下以多进程的方式来工作
  - 一个master进程，多个worker进程。master进程负责监控管理worker进程，worker进程负责处理网络事件
  - 一般worker个数与CPU个数一致，以减少进程间切换的开销，甚至把每个worker进程绑定到一个固定的CPU上面：并行

![](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030142136.png)

- master收到重新加载指令，会重新加载配置文件，然后启动新的进程，使用的新worker来接受新请求，并通知老worker可以撤销了
  - 老worker将不会接受新连接，处理完手中正在处理的请求就会退出
- 当一个新连接请求到来时，每个worker都能接收到通知。多个worker间通过锁机制，竞争来自客户端的连接，竞争到的进程负责处理这个连接上的请求
- worker进程里只有一个主线程，避免了线程间切换开销。但只有一个线程为什么能同时接收上万请求？
  - Nginx将一个请求划分为多个阶段来异步处理，每个阶段只是处理请求的一部分，如果请求的这一部分发生阻塞，Nginx不会等待，它会处理其他请求的某一部分

###### Nginx支持的负载均衡调度方式例

- 轮询（缺省）：每个请求按到来的顺序逐一分配到不同的后端服务器。在轮询中，如果服务器down掉了，会自动剔除该服务器
  - 适合服务器配置相当，无状态且响应快的服务使用
- weight轮询：接收到的请求按照权重分配到不同的后端服务，权重越大的服务器，被分配到请求的几率越大
  - 比较适合服务器的硬件配置差别比较大的情况
- ip_hash：每个请求按访问ip的hash结果分配，这样每个客户固定访问一个后端服务器，在一定程度上解决了集群部署环境下session共享问题
  - 适合有状态服务
- least_conn：把请求转发给连接数较少的后端服务器
  - 适合请求处理时间长短不一造成服务器过载的情况
- 第三方策略：第三方的负载均衡策略的实现需要安装第三方插件。
  - fair：按照服务器端的响应时间来分配请求，响应时间短的优先分配。
  - url_hash：按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，要配合缓存命中来使用。

##### 多级负载均衡例

- 流量大时，多个Nginx组成集群
- 可在Nginx前再加LVS，如果一台 LVS 不够，可多加几台，DNS 在解析域名的时候随机分发到其中一台
- 如果做多级混合负载均衡，通常是低层的在前，高层的在后

![](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/12632/20221030143124.png)

<a href="https://www.zhihu.com/question/22610352/answer/2049786576" target="_blank">服务器集群负载均衡原理？ - 码海的回答 - 知乎</a>

## 7 本章小节

- 分布式系统中，进程是基本部分，它们协作实现了分布式系统的功能，也构成了不同机器间通信的基础
- 使用多线程可以构建更高效的服务器，而且可以有效地支持并发
- 多种IO模型，根据应用需求选择合适的
- 客户进程一般实现用户接口，通过隐藏与服务器通信的细节，可获得更好的分布透明性
- 服务器可以是迭代的也可以是并发的，可以实现一种服务也可以实现多种服务
- 服务器可以是无状态的也可以是有状态的
- 很多服务器组织成集群，通常需隐藏集群内部细节，使用单访问点将请求消息基于负载均衡策略转发给服务器


